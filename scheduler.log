Waiting for host: airflow-postgresql.tmp 5432
/usr/local/lib/python3.9/site-packages/airflow/configuration.py:434: DeprecationWarning: The auth_backend option in [api] has been renamed to auth_backends - the old setting has been used, but please update your config.
  option = self._get_option_from_config_file(deprecated_key, deprecated_section, key, kwargs, section)
/usr/local/lib/python3.9/site-packages/airflow/configuration.py:372: FutureWarning: The 'auth_backends' setting in [api] has the old default value of 'airflow.api.auth.backend.deny_all'. This value has been changed to 'airflow.api.auth.backend.session' in the running config, but please update your config before Apache Airflow 3.0.
  warnings.warn(
/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/relationships.py:3441 SAWarning: relationship 'DagRun.serialized_dag' will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with relationship(s): 'BaseXCom.dag_run' (copies xcom.dag_id to dag_run.dag_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   The 'overlaps' parameter may be used to remove this warning. (Background on this error at: http://sqlalche.me/e/14/qzyx)
/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/relationships.py:3441 SAWarning: relationship 'SerializedDagModel.dag_runs' will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with relationship(s): 'BaseXCom.dag_run' (copies xcom.dag_id to dag_run.dag_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   The 'overlaps' parameter may be used to remove this warning. (Background on this error at: http://sqlalche.me/e/14/qzyx)
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2022-03-03 08:21:36,473] {scheduler_job.py:644} INFO - Starting the scheduler
[2022-03-03 08:21:36,473] {scheduler_job.py:649} INFO - Processing each file at most -1 times
[2022-03-03 08:21:36,668] {executor_loader.py:101} INFO - Loaded executor: CeleryExecutor
[2022-03-03 08:21:36,676] {manager.py:154} INFO - Launched DagFileProcessorManager with pid: 18
[2022-03-03 08:21:36,683] {settings.py:55} INFO - Configured default timezone Timezone('UTC')
[2022-03-03 08:21:36,685] {settings.py:525} INFO - Loaded airflow_local_settings from /usr/local/airflow/config/airflow_local_settings.py .
[2022-03-03 08:21:36,777] {scheduler_job.py:1165} INFO - Resetting orphaned tasks for active dag runs
[2022-03-03 08:21:45,392] {update_checks.py:128} INFO - Checking for new version of Astronomer Certified Airflow, previous check was performed at None
[2022-03-03 08:21:45,671] {update_checks.py:84} INFO - Check finished, next check in 86400.0 seconds
[2022-03-03 08:22:07,685] {scheduler_job.py:982} INFO - DAG example_sql_sensor is at (or above) max_active_runs (1 of 1), not creating any more runs
[2022-03-03 08:22:07,756] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:18:36.673470+00:00 [scheduled]>
[2022-03-03 08:22:07,759] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:07,760] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 0/16 running and queued tasks
[2022-03-03 08:22:07,761] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:18:36.673470+00:00 [scheduled]>
[2022-03-03 08:22:07,767] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='prepare_table', run_id='scheduled__2022-03-03T08:18:36.673470+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:07,767] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'prepare_table', 'scheduled__2022-03-03T08:18:36.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:22:07,938] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.prepare_table run_id=scheduled__2022-03-03T08:18:36.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:07,946] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:18:36.673470+00:00 [queued]> to 20eb49fa-85a6-44d4-b44d-10322904c46e
[2022-03-03 08:22:09,118] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.prepare_table run_id=scheduled__2022-03-03T08:18:36.673470+00:00 exited with status success for try_number 1
[2022-03-03 08:22:09,123] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=example_sql_sensor, task_id=prepare_table, run_id=scheduled__2022-03-03T08:18:36.673470+00:00, run_start_date=2022-03-03 08:22:08.090777+00:00, run_end_date=2022-03-03 08:22:08.431609+00:00, run_duration=0.340832, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=2, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:10,176] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: example_sql_sensor.drop_table_last scheduled__2022-03-03T08:18:36.673470+00:00 [scheduled]>
[2022-03-03 08:22:10,177] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:10,177] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 0/16 running and queued tasks
[2022-03-03 08:22:10,178] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: example_sql_sensor.drop_table_last scheduled__2022-03-03T08:18:36.673470+00:00 [scheduled]>
[2022-03-03 08:22:10,179] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='drop_table_last', run_id='scheduled__2022-03-03T08:18:36.673470+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:22:10,179] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'drop_table_last', 'scheduled__2022-03-03T08:18:36.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:22:10,243] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.drop_table_last run_id=scheduled__2022-03-03T08:18:36.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:10,248] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.drop_table_last scheduled__2022-03-03T08:18:36.673470+00:00 [queued]> to d3db09f6-5c2c-4dca-86b4-98bf430c14ba
[2022-03-03 08:22:11,397] {scheduler_job.py:982} INFO - DAG sixteen_sleep_grains is at (or above) max_active_runs (1 of 1), not creating any more runs
[2022-03-03 08:22:11,463] {dagrun.py:534} ERROR - Marking run <DagRun example_sql_sensor @ 2022-03-03 08:18:36.673470+00:00: scheduled__2022-03-03T08:18:36.673470+00:00, externally triggered: False> failed
[2022-03-03 08:22:11,463] {dagrun.py:594} INFO - DagRun Finished: dag_id=example_sql_sensor, execution_date=2022-03-03 08:18:36.673470+00:00, run_id=scheduled__2022-03-03T08:18:36.673470+00:00, run_start_date=2022-03-03 08:22:07.696755+00:00, run_end_date=2022-03-03 08:22:11.463829+00:00, run_duration=3.767074, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2022-03-03 08:18:36.673470+00:00, data_interval_end=2022-03-03 08:21:37.673470+00:00, dag_hash=9fc362d4b01672615cdf029e7f93196e
[2022-03-03 08:22:11,471] {dag.py:2921} INFO - Setting next_dagrun for example_sql_sensor to 2022-03-03T08:21:37.673470+00:00, run_after=2022-03-03T08:24:38.673470+00:00
[2022-03-03 08:22:11,501] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.drop_table_last run_id=scheduled__2022-03-03T08:18:36.673470+00:00 exited with status success for try_number 1
[2022-03-03 08:22:11,506] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=example_sql_sensor, task_id=drop_table_last, run_id=scheduled__2022-03-03T08:18:36.673470+00:00, run_start_date=2022-03-03 08:22:10.394453+00:00, run_end_date=2022-03-03 08:22:10.700415+00:00, run_duration=0.305962, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=3, pool=default_pool, queue=celery, priority_weight=1, operator=PostgresOperator
[2022-03-03 08:22:12,604] {scheduler_job.py:311} INFO - 16 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.0_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.8.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.15.0_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.0_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.0_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.0_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.7.0_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.0_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.0_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.0_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.0_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.6.0_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.0_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.1.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:12,606] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 16 task instances ready to be queued
[2022-03-03 08:22:12,607] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 0/16 running and queued tasks
[2022-03-03 08:22:12,607] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 1/16 running and queued tasks
[2022-03-03 08:22:12,607] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 2/16 running and queued tasks
[2022-03-03 08:22:12,607] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 3/16 running and queued tasks
[2022-03-03 08:22:12,608] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 4/16 running and queued tasks
[2022-03-03 08:22:12,608] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 5/16 running and queued tasks
[2022-03-03 08:22:12,608] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 6/16 running and queued tasks
[2022-03-03 08:22:12,608] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 7/16 running and queued tasks
[2022-03-03 08:22:12,608] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 8/16 running and queued tasks
[2022-03-03 08:22:12,609] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 9/16 running and queued tasks
[2022-03-03 08:22:12,609] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 10/16 running and queued tasks
[2022-03-03 08:22:12,609] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 11/16 running and queued tasks
[2022-03-03 08:22:12,609] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:22:12,609] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:12,610] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:12,610] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:12,610] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.0_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.8.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.15.0_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.0_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.0_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.0_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.7.0_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.0_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.0_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.0_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.0_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.6.0_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.0_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.1.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:12,618] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.0_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue celery
[2022-03-03 08:22:12,619] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.0_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,619] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.0_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue celery
[2022-03-03 08:22:12,619] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.0_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,619] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.0_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue celery
[2022-03-03 08:22:12,620] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.0_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,620] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.0_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:12,620] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.0_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,620] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.0_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:12,620] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.0_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,620] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.0_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:12,621] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.0_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,621] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.0_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:12,621] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.0_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,621] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.0_sleep_2', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:12,621] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.0_sleep_2', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,622] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='9.0_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:12,622] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '9.0_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,622] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='2.0_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:12,622] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '2.0_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,622] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='12.0_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:12,622] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '12.0_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,622] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='13.0_sleep_20', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:12,622] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '13.0_sleep_20', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,622] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='10.0_sleep_17', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:12,622] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '10.0_sleep_17', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,623] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='6.0_sleep_16', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:12,623] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '6.0_sleep_16', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,623] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='11.0_sleep_27', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:12,623] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '11.0_sleep_27', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:12,623] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='1.0_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:12,623] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '1.0_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:17,964] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.0_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:17,964] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:17,964] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.0_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:17,964] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.0_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:17,965] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.0_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,035] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,035] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.0_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.0_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.0_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.0_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.0_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.0_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,036] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.0_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,037] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.0_sleep_27 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,037] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:18,146] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.2.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to be2eb22a-8039-4d0f-ab1a-1f719b506c4f
[2022-03-03 08:22:18,146] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.10.0_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to f45cfc81-1371-4d5c-8bbd-1929a5175656
[2022-03-03 08:22:18,153] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.1.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to ed274a50-7461-4f63-a5ab-0e8ca10bd65f
[2022-03-03 08:22:18,154] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.0_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 2c1655b7-162d-4d23-ba2f-201801aaacd0
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.0_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 386f7f94-ca80-4c28-bee1-edff95e1c5bf
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.12.0_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 18faa856-4d1b-42dd-8fdf-8a3cf494792b
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.0_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to dab3187e-fb8a-4af4-9af1-1c6ee9be9846
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.11.0_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to b3c29c30-12e6-4346-bc4d-aa5e5cac71eb
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.6.0_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 270bcf8c-8361-44cf-95f8-d58465ca13dc
[2022-03-03 08:22:18,155] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.0_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 701f0df3-a8b8-414c-9c77-9ae762b4ad16
[2022-03-03 08:22:18,156] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.0_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [running]> to 8cb94cd8-575f-4050-9d03-396a8dd67755
[2022-03-03 08:22:19,694] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.3.1_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:19,695] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:19,695] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:19,696] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.3.1_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:19,698] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.1_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:19,698] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.1_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:19,744] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.1_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:19,744] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.0_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:19,754] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.1_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 5656475b-626d-4267-bf90-5fe446eea827
[2022-03-03 08:22:19,754] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.0_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.443240+00:00, run_end_date=2022-03-03 08:22:19.375999+00:00, run_duration=1.932759, state=success, executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:20,900] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.7.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:20,903] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:20,903] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:20,904] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.7.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:20,907] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.1_sleep_16', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:20,907] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.1_sleep_16', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:20,960] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.1_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:20,960] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.0_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:20,967] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 9b39203f-ff9b-4386-985e-dfe926c6f2b3
[2022-03-03 08:22:20,968] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.0_sleep_2, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:16.852608+00:00, run_end_date=2022-03-03 08:22:19.687048+00:00, run_duration=2.83444, state=success, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:22,122] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.1_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:22,125] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:22,125] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:22,126] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:22,126] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.1_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:22,132] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.1_sleep_9', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue celery
[2022-03-03 08:22:22,132] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.1_sleep_9', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:22,133] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.2_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:22,133] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.2_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:22,452] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.1_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:22,452] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.2_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:22,452] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.0_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:22,452] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.1_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:22,459] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.1_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 2e33cb34-fa05-4a97-8457-e2b11e0b8e5d
[2022-03-03 08:22:22,459] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to d63a16db-e7b8-42d4-ae8d-f338ae2f4c16
[2022-03-03 08:22:22,459] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.1_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:20.140815+00:00, run_end_date=2022-03-03 08:22:21.566318+00:00, run_duration=1.425503, state=success, executor_state=success, try_number=1, max_tries=0, job_id=20, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:22,460] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.0_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:15.833769+00:00, run_end_date=2022-03-03 08:22:21.178818+00:00, run_duration=5.345049, state=success, executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=celery, priority_weight=10, operator=PythonOperator
[2022-03-03 08:22:23,539] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.1_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:23,541] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:23,542] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:23,542] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.1_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:23,549] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.1_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:23,549] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.1_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:23,860] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.1_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:23,931] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.0_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:23,946] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.1_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 23e9d124-da78-468d-8dee-12810fc27cf7
[2022-03-03 08:22:23,946] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.0_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:18.769968+00:00, run_end_date=2022-03-03 08:22:22.250185+00:00, run_duration=3.480217, state=success, executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=celery, priority_weight=9, operator=PythonOperator
[2022-03-03 08:22:24,147] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.12.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,151] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:24,152] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:24,152] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.12.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,158] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='12.1_sleep_15', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:24,158] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '12.1_sleep_15', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:24,332] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.1_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:24,332] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.0_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:24,346] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.12.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 06122d03-a8de-458f-9156-9d10bfb256c0
[2022-03-03 08:22:24,347] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=12.0_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.135940+00:00, run_end_date=2022-03-03 08:22:22.972982+00:00, run_duration=5.837042, state=success, executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:24,461] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.1_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,463] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:24,463] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:24,464] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.1_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,533] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.1_sleep_12', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue celery
[2022-03-03 08:22:24,533] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.1_sleep_12', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:24,732] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.1_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:24,733] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:24,741] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.1_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c57857de-7acd-4fba-98cb-64249a594c27
[2022-03-03 08:22:24,742] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.0_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:15.043628+00:00, run_end_date=2022-03-03 08:22:23.166477+00:00, run_duration=8.122849, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=celery, priority_weight=10, operator=PythonOperator
[2022-03-03 08:22:24,852] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.9.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,856] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:24,856] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:24,856] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.9.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:24,863] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='9.1_sleep_15', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:24,863] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '9.1_sleep_15', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:25,141] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.1_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:25,141] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.0_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:25,154] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.9.1_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 639024bc-f3f6-4f7a-9684-5bbc2c0cd9a2
[2022-03-03 08:22:25,154] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=9.0_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:18.542989+00:00, run_end_date=2022-03-03 08:22:23.754068+00:00, run_duration=5.211079, state=success, executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:26,757] {scheduler_job.py:311} INFO - 3 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.14.1_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.1_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.1.1_sleep_30 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:26,759] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 3 task instances ready to be queued
[2022-03-03 08:22:26,759] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:26,759] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:26,759] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:26,761] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.14.1_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.1_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.1.1_sleep_30 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:26,764] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.1_sleep_2', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:26,765] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.1_sleep_2', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:26,765] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='2.1_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:26,766] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '2.1_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:26,766] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='1.1_sleep_30', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:26,767] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '1.1_sleep_30', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:27,164] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.1_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:27,164] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.1_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:27,164] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.1_sleep_30 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:27,164] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:27,165] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:27,165] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.0_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:27,242] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.1.1_sleep_30 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 5839137d-15ed-4dce-a464-bfe764bb7260
[2022-03-03 08:22:27,242] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.1_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f0c27ca9-7cba-4426-903b-bf69b6ca9885
[2022-03-03 08:22:27,243] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.2.1_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 245e9f86-34ce-4ef1-a843-2a80b0d33b36
[2022-03-03 08:22:27,243] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.0_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:18.048749+00:00, run_end_date=2022-03-03 08:22:25.053296+00:00, run_duration=7.004547, state=success, executor_state=success, try_number=1, max_tries=0, job_id=15, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:27,245] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=2.0_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.855010+00:00, run_end_date=2022-03-03 08:22:25.040175+00:00, run_duration=7.185165, state=success, executor_state=success, try_number=1, max_tries=0, job_id=14, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:27,245] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=1.0_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.557799+00:00, run_end_date=2022-03-03 08:22:24.951603+00:00, run_duration=7.393804, state=success, executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:28,418] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.16.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.3_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:28,421] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:28,421] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:28,421] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:28,422] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.16.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.3_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:28,425] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.1_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:28,425] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.1_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:28,426] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.3_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:28,426] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.3_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:28,661] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.1_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:28,661] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.3_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:28,662] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.0_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:28,662] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.2_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:28,677] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.3_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 22a5bbf8-a316-4007-a3ba-beeda64c1ed5
[2022-03-03 08:22:28,677] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 3cc7fa6a-4f78-48c7-a8e7-ddf686f494aa
[2022-03-03 08:22:28,677] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.0_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.256388+00:00, run_end_date=2022-03-03 08:22:28.162562+00:00, run_duration=10.906174, state=success, executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:28,678] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.2_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:23.135088+00:00, run_end_date=2022-03-03 08:22:27.063591+00:00, run_duration=3.928503, state=success, executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:30,330] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.14.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:30,332] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:30,332] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:30,332] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:30,333] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.14.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:30,338] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.2_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:30,338] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.2_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:30,338] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.1_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:30,339] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.1_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:30,636] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.2_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:30,636] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.1_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:30,636] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.0_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:30,636] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.1_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:30,644] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.1_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 8168a8a5-32ee-4f82-8105-8238f886f111
[2022-03-03 08:22:30,644] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to e5deb7e9-a718-4a40-9ff1-46ecc31d369a
[2022-03-03 08:22:30,644] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.1_sleep_2, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:27.737860+00:00, run_end_date=2022-03-03 08:22:30.058105+00:00, run_duration=2.320245, state=success, executor_state=success, try_number=1, max_tries=0, job_id=28, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:30,644] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.0_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:18.333280+00:00, run_end_date=2022-03-03 08:22:29.154658+00:00, run_duration=10.821378, state=success, executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:31,849] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:31,851] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:31,851] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:31,852] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:31,855] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.2_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:31,856] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.2_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:31,930] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.2_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:31,930] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.1_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:31,936] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.2_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to d7d8096b-bca5-41f6-b9c2-0fb096cd37e3
[2022-03-03 08:22:31,937] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.1_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:24.855173+00:00, run_end_date=2022-03-03 08:22:30.738540+00:00, run_duration=5.883367, state=success, executor_state=success, try_number=1, max_tries=0, job_id=24, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:33,149] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.2_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:33,153] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:33,153] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:33,153] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:33,154] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.2_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:33,160] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.2_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:33,160] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.2_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:33,160] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='2.2_sleep_20', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:33,160] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '2.2_sleep_20', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:33,518] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.2_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:33,518] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.2_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:33,519] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.1_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:33,519] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.1_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:33,599] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.2.2_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 7d5ed9a1-1cda-4a13-ae0e-01bd1d6de154
[2022-03-03 08:22:33,600] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to aa44b7dc-4d0f-4833-98dc-f8d4a6433f47
[2022-03-03 08:22:33,600] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.1_sleep_9, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:23.050687+00:00, run_end_date=2022-03-03 08:22:32.873804+00:00, run_duration=9.823117, state=success, executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=celery, priority_weight=9, operator=PythonOperator
[2022-03-03 08:22:33,601] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=2.1_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:27.651275+00:00, run_end_date=2022-03-03 08:22:32.046961+00:00, run_duration=4.395686, state=success, executor_state=success, try_number=1, max_tries=0, job_id=29, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:34,409] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.6.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:34,411] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:34,411] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:34,412] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.6.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:34,414] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='6.1_sleep_16', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:34,415] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '6.1_sleep_16', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:34,465] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.1_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:34,465] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.0_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:34,501] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.6.1_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 6cc73757-e133-42b1-912b-8d4e378c99c0
[2022-03-03 08:22:34,501] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=6.0_sleep_16, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:16.241382+00:00, run_end_date=2022-03-03 08:22:33.417270+00:00, run_duration=17.175888, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:35,652] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.16.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:35,699] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:35,699] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:35,700] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.16.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:35,703] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.2_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:35,703] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.2_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:35,760] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.2_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:35,760] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.1_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:35,801] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.2_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c1da9550-06c1-481f-bbbf-fa4e379f0248
[2022-03-03 08:22:35,801] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.1_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:28.990708+00:00, run_end_date=2022-03-03 08:22:35.340873+00:00, run_duration=6.350165, state=success, executor_state=success, try_number=1, max_tries=0, job_id=31, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:35,899] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:35,901] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:35,901] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:35,902] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:35,906] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.3_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:35,906] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.3_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:36,014] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:36,014] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.2_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:36,021] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 91540102-ffe5-485c-8231-b364d869be38
[2022-03-03 08:22:36,021] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.2_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:32.255053+00:00, run_end_date=2022-03-03 08:22:35.567013+00:00, run_duration=3.31196, state=success, executor_state=success, try_number=1, max_tries=0, job_id=35, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:37,361] {scheduler_job.py:311} INFO - 3 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.14.3_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.1_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:37,366] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 3 task instances ready to be queued
[2022-03-03 08:22:37,366] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:37,367] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:37,367] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:37,368] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.14.3_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.1_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:37,372] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.3_sleep_13', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:37,373] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.3_sleep_13', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:37,374] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.4_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:37,374] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.4_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:37,375] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='10.1_sleep_17', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:37,375] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '10.1_sleep_17', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:37,811] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.3_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:37,811] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.4_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:37,811] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.1_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:37,811] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.0_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:37,811] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.3_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:37,812] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.2_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:37,824] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.10.1_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 14584d83-706b-42d4-8b49-1788b7a911f7
[2022-03-03 08:22:37,824] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.3_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 7bc0c652-6f79-43da-89fb-d56eb0965736
[2022-03-03 08:22:37,825] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to cb793626-56ac-42c1-941f-fe65a49de6c6
[2022-03-03 08:22:37,825] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.3_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:29.043313+00:00, run_end_date=2022-03-03 08:22:36.601686+00:00, run_duration=7.558373, state=success, executor_state=success, try_number=1, max_tries=0, job_id=32, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:37,825] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.2_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:31.030610+00:00, run_end_date=2022-03-03 08:22:36.514324+00:00, run_duration=5.483714, state=success, executor_state=success, try_number=1, max_tries=0, job_id=33, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:37,825] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=10.0_sleep_17, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:17.735515+00:00, run_end_date=2022-03-03 08:22:35.855302+00:00, run_duration=18.119787, state=success, executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:38,820] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.5.2_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.7.2_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:38,824] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:38,824] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:38,824] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:38,825] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.5.2_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.7.2_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:38,833] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.2_sleep_8', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:38,833] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.2_sleep_8', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:38,833] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.2_sleep_18', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:38,833] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.2_sleep_18', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:39,320] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.2_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:39,320] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.2_sleep_18 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:39,320] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.1_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:39,320] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.1_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:39,329] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.2_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to e17bc07b-8ad5-494a-bde4-56e689734172
[2022-03-03 08:22:39,330] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.2_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 40334aeb-762f-44dc-a856-6273cd39c313
[2022-03-03 08:22:39,330] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.1_sleep_16, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:21.197534+00:00, run_end_date=2022-03-03 08:22:37.618288+00:00, run_duration=16.420754, state=success, executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:39,330] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.1_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:31.072936+00:00, run_end_date=2022-03-03 08:22:37.524899+00:00, run_duration=6.451963, state=success, executor_state=success, try_number=1, max_tries=0, job_id=34, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:39,623] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.1_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:39,625] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:39,625] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:39,626] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:39,626] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.1_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:39,634] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.2_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue celery
[2022-03-03 08:22:39,634] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.2_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:39,635] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='13.1_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:39,635] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '13.1_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:40,218] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.2_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:40,218] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.1_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:40,218] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.0_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:40,218] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.1_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:40,230] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.2_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f3d87b14-a25e-4758-a560-18a3f3678582
[2022-03-03 08:22:40,299] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.13.1_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 77d2049f-04ec-49c8-b0aa-a4cd8ef62635
[2022-03-03 08:22:40,299] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=13.0_sleep_20, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:18.659072+00:00, run_end_date=2022-03-03 08:22:39.421365+00:00, run_duration=20.762293, state=success, executor_state=success, try_number=1, max_tries=0, job_id=18, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:40,300] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.1_sleep_12, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:26.094123+00:00, run_end_date=2022-03-03 08:22:38.739607+00:00, run_duration=12.645484, state=success, executor_state=success, try_number=1, max_tries=0, job_id=27, pool=default_pool, queue=celery, priority_weight=9, operator=PythonOperator
[2022-03-03 08:22:42,976] {scheduler_job.py:311} INFO - 5 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.3_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.15.4_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.2_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:42,979] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 5 task instances ready to be queued
[2022-03-03 08:22:42,979] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 11/16 running and queued tasks
[2022-03-03 08:22:42,979] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:22:42,979] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:42,980] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:42,980] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:42,980] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.3_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.15.4_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.2_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:42,984] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.3_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:42,984] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.3_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:42,984] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.3_sleep_15', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:42,985] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.3_sleep_15', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:42,985] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.4_sleep_9', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:22:42,985] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.4_sleep_9', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:42,985] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='9.2_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:42,985] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '9.2_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:42,986] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='12.2_sleep_13', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:42,986] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '12.2_sleep_13', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:44,198] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:44,199] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.3_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:44,199] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.4_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:44,199] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.2_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:44,199] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.2_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:44,199] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.1_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:44,200] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.1_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:44,200] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.2_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:44,202] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.2_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:44,204] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:44,302] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 1951180b-7352-485b-bac5-3f4b8f3b2b9e
[2022-03-03 08:22:44,302] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.4_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 00f28f4d-5223-400b-a752-184f4de9e59b
[2022-03-03 08:22:44,302] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.12.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to e13169ba-ac09-4637-8a39-547c512dfb4a
[2022-03-03 08:22:44,302] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.9.2_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c9999a46-e357-47c6-a738-9a4a115621cd
[2022-03-03 08:22:44,302] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.3_sleep_15 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f8b24baa-d840-4e16-a413-84012712ceba
[2022-03-03 08:22:44,303] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.2_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:37.109883+00:00, run_end_date=2022-03-03 08:22:42.342960+00:00, run_duration=5.233077, state=success, executor_state=success, try_number=1, max_tries=0, job_id=40, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:44,303] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=9.1_sleep_15, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:26.049039+00:00, run_end_date=2022-03-03 08:22:42.055381+00:00, run_duration=16.006342, state=success, executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:44,303] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=12.1_sleep_15, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:26.004582+00:00, run_end_date=2022-03-03 08:22:41.516706+00:00, run_duration=15.512124, state=success, executor_state=success, try_number=1, max_tries=0, job_id=25, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:44,303] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.3_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:37.056091+00:00, run_end_date=2022-03-03 08:22:41.337484+00:00, run_duration=4.281393, state=success, executor_state=success, try_number=1, max_tries=0, job_id=39, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:22:44,303] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.2_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:33.924739+00:00, run_end_date=2022-03-03 08:22:41.312729+00:00, run_duration=7.38799, state=success, executor_state=success, try_number=1, max_tries=0, job_id=36, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:46,771] {scheduler_job.py:311} INFO - 3 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.3.5_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.1_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:46,774] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 3 task instances ready to be queued
[2022-03-03 08:22:46,774] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:46,774] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:46,774] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:46,775] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.3.5_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.1_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:46,779] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.5_sleep_16', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:46,779] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.5_sleep_16', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:46,779] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='13.2_sleep_13', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:46,779] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '13.2_sleep_13', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:46,780] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='11.1_sleep_8', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:46,780] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '11.1_sleep_8', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:47,111] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.5_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:47,111] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.2_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:47,111] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.1_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:47,111] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.0_sleep_27 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:47,112] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.4_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:47,112] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.1_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:47,121] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.11.1_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 0f41a941-10b0-4ed6-a3cf-50d0d3c2d3a7
[2022-03-03 08:22:47,122] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.13.2_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 6a00309f-df32-4d13-86f1-1067481deb90
[2022-03-03 08:22:47,122] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.5_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 55d154ac-93fe-4b54-a43e-154d8761dac0
[2022-03-03 08:22:47,122] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.4_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:38.469522+00:00, run_end_date=2022-03-03 08:22:46.025668+00:00, run_duration=7.556146, state=success, executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:47,122] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=13.1_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:41.036257+00:00, run_end_date=2022-03-03 08:22:45.123825+00:00, run_duration=4.087568, state=success, executor_state=success, try_number=1, max_tries=0, job_id=46, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:22:47,122] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=11.0_sleep_27, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:16.549634+00:00, run_end_date=2022-03-03 08:22:45.106978+00:00, run_duration=28.557344, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:49,440] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:49,444] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:49,444] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:49,445] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:49,445] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:49,449] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.3_sleep_12', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue celery
[2022-03-03 08:22:49,450] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.3_sleep_12', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:49,450] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.3_sleep_12', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:49,450] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.3_sleep_12', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:49,809] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.3_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:49,810] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.3_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:49,810] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.2_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:49,810] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.2_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:49,810] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:49,824] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to fddc379b-f8b8-476b-8375-195e42cd120f
[2022-03-03 08:22:49,824] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.3_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to ad68b935-c18d-4445-aa1c-e5580cc69e98
[2022-03-03 08:22:49,824] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.3_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:44.608849+00:00, run_end_date=2022-03-03 08:22:49.252413+00:00, run_duration=4.643564, state=success, executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:22:49,825] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.2_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:41.221346+00:00, run_end_date=2022-03-03 08:22:48.862766+00:00, run_duration=7.64142, state=success, executor_state=success, try_number=1, max_tries=0, job_id=47, pool=default_pool, queue=celery, priority_weight=8, operator=PythonOperator
[2022-03-03 08:22:49,825] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.2_sleep_8, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:40.106059+00:00, run_end_date=2022-03-03 08:22:48.851163+00:00, run_duration=8.745104, state=success, executor_state=success, try_number=1, max_tries=0, job_id=44, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:50,037] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.4_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:50,041] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:50,041] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:50,042] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.4_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:50,097] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.4_sleep_8', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:22:50,097] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.4_sleep_8', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:50,210] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.4_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:50,220] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.4_sleep_8 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 3dc8ddd2-40de-4ac1-8878-9fcfddecfccb
[2022-03-03 08:22:51,919] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.6.2_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:51,922] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:51,923] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:51,924] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.6.2_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:51,927] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='6.2_sleep_27', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:22:51,927] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '6.2_sleep_27', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:52,124] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.2_sleep_27 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:52,125] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.1_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:52,125] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.3_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:52,138] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.6.2_sleep_27 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 9bee96ee-ca09-4bcb-9c25-d2aeef04eaec
[2022-03-03 08:22:52,138] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.3_sleep_13, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:38.365230+00:00, run_end_date=2022-03-03 08:22:51.733328+00:00, run_duration=13.368098, state=success, executor_state=success, try_number=1, max_tries=0, job_id=42, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:52,138] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=6.1_sleep_16, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:34.688913+00:00, run_end_date=2022-03-03 08:22:50.848002+00:00, run_duration=16.159089, state=success, executor_state=success, try_number=1, max_tries=0, job_id=38, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:22:52,328] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.14.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:52,330] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:52,331] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:52,331] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.14.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:52,334] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.4_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:52,334] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.4_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:52,516] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.4_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:52,524] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.4_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 3effce09-7731-4735-8e97-2b3adf864370
[2022-03-03 08:22:55,145] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.5_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:55,147] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:55,147] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:55,147] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:55,148] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.5_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:55,154] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.5_sleep_9', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:22:55,154] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.5_sleep_9', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:55,154] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='2.3_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:55,154] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '2.3_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:55,603] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.5_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:55,603] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:55,603] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.2_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:55,604] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.4_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:55,604] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.2_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:55,613] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.2.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 0dc33ed9-16a9-475e-820c-e4871b0511bf
[2022-03-03 08:22:55,613] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.5_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 872938fa-fd08-4eae-95b8-f1a0556bfeed
[2022-03-03 08:22:55,613] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=9.2_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:44.501702+00:00, run_end_date=2022-03-03 08:22:55.037067+00:00, run_duration=10.535365, state=success, executor_state=success, try_number=1, max_tries=0, job_id=48, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:55,614] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.4_sleep_9, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:44.655743+00:00, run_end_date=2022-03-03 08:22:54.541579+00:00, run_duration=9.885836, state=success, executor_state=success, try_number=1, max_tries=0, job_id=50, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:22:55,614] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=2.2_sleep_20, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:33.962643+00:00, run_end_date=2022-03-03 08:22:54.240608+00:00, run_duration=20.277965, state=success, executor_state=success, try_number=1, max_tries=0, job_id=37, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:55,812] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.9.3_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:55,815] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:55,816] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:55,816] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.9.3_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:55,821] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='9.3_sleep_17', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:55,821] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '9.3_sleep_17', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:56,019] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.3_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:56,027] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.9.3_sleep_17 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to e0e24b52-c841-482e-8307-f90e04df9264
[2022-03-03 08:22:57,375] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.10.2_sleep_11 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:57,377] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:57,378] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:57,378] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:22:57,378] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.10.2_sleep_11 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.11.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:57,381] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='10.2_sleep_11', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:57,381] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '10.2_sleep_11', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:57,382] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='11.2_sleep_24', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:22:57,382] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '11.2_sleep_24', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:57,623] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.2_sleep_11 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:57,624] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.2_sleep_24 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:57,624] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.1_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:57,624] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.1_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:57,637] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.11.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 67dffbec-5da3-43c8-a662-66300aa7cf99
[2022-03-03 08:22:57,637] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.10.2_sleep_11 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 7fe65b25-c2ad-4bff-b1e2-d33c82f74a1c
[2022-03-03 08:22:57,638] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=10.1_sleep_17, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:38.431114+00:00, run_end_date=2022-03-03 08:22:55.916128+00:00, run_duration=17.485014, state=success, executor_state=success, try_number=1, max_tries=0, job_id=41, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:57,638] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=11.1_sleep_8, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:47.514568+00:00, run_end_date=2022-03-03 08:22:55.835511+00:00, run_duration=8.320943, state=success, executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:22:58,872] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.1.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:58,875] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 1 task instances ready to be queued
[2022-03-03 08:22:58,875] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:58,876] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.1.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:58,880] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='1.2_sleep_24', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:22:58,880] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '1.2_sleep_24', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:58,937] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.2_sleep_24 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:58,937] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.1_sleep_30 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:59,000] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.1.2_sleep_24 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 6966db1e-c911-45fb-a52f-ec41b9e49506
[2022-03-03 08:22:59,000] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=1.1_sleep_30, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:27.778977+00:00, run_end_date=2022-03-03 08:22:58.061104+00:00, run_duration=30.282127, state=success, executor_state=success, try_number=1, max_tries=0, job_id=30, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:22:59,140] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.7.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.3_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:59,143] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:22:59,143] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:22:59,143] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:22:59,144] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.7.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.3_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:22:59,148] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.3_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:22:59,148] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.3_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:59,149] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='12.3_sleep_9', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:22:59,149] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '12.3_sleep_9', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:22:59,604] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:59,604] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.3_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:22:59,604] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.2_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:59,616] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.3_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to dab141d5-6cae-4281-90fa-73df67d2e47d
[2022-03-03 08:22:59,617] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.12.3_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 48361627-030c-4899-81d8-0b543d1fc3f0
[2022-03-03 08:22:59,617] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=12.2_sleep_13, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:44.940387+00:00, run_end_date=2022-03-03 08:22:58.764489+00:00, run_duration=13.824102, state=success, executor_state=success, try_number=1, max_tries=0, job_id=52, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:22:59,737] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.2_sleep_18 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:22:59,746] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.2_sleep_18, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:40.217403+00:00, run_end_date=2022-03-03 08:22:59.020688+00:00, run_duration=18.803285, state=success, executor_state=success, try_number=1, max_tries=0, job_id=45, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:00,044] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.5_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:00,048] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:00,096] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:00,103] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.5_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:00,106] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.5_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:23:00,106] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.5_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:00,304] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.5_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:00,304] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.4_sleep_8 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:00,315] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.5_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 502cffa4-8403-4b05-85cc-340cc600f2d9
[2022-03-03 08:23:00,315] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.4_sleep_8, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:50.918291+00:00, run_end_date=2022-03-03 08:22:59.131436+00:00, run_duration=8.213145, state=success, executor_state=success, try_number=1, max_tries=0, job_id=58, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:23:01,198] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.16.4_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:01,201] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:01,201] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:23:01,202] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.16.4_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:01,205] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.4_sleep_13', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:23:01,205] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.4_sleep_13', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:01,397] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.4_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:01,398] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.3_sleep_15 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:01,407] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.3_sleep_15, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:44.822349+00:00, run_end_date=2022-03-03 08:23:00.737767+00:00, run_duration=15.915418, state=success, executor_state=success, try_number=1, max_tries=0, job_id=51, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:23:01,407] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.4_sleep_13 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f85ded33-e55d-4d6b-9682-6e215fa3984b
[2022-03-03 08:23:02,678] {scheduler_job.py:311} INFO - 4 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.5_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.3_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.4_sleep_23 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:02,681] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 4 task instances ready to be queued
[2022-03-03 08:23:02,681] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:23:02,681] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:23:02,682] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:02,682] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:02,683] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.5_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.13.3_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.2.4_sleep_23 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:02,689] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.4_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue celery
[2022-03-03 08:23:02,689] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.4_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:02,689] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.5_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:02,690] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.5_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:02,690] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='13.3_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:02,690] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '13.3_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:02,690] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='2.4_sleep_23', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:02,693] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '2.4_sleep_23', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.4_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.5_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.3_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.4_sleep_23 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.2_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.3_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.4_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:03,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:03,692] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=2.3_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:56.312814+00:00, run_end_date=2022-03-03 08:23:01.315857+00:00, run_duration=5.003043, state=success, executor_state=success, try_number=1, max_tries=0, job_id=61, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:03,693] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.2.4_sleep_23 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 8f6b627d-e2a7-4721-aa40-76879fbb5e3f
[2022-03-03 08:23:03,693] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.3_sleep_12, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:50.314009+00:00, run_end_date=2022-03-03 08:23:02.585517+00:00, run_duration=12.271508, state=success, executor_state=success, try_number=1, max_tries=0, job_id=56, pool=default_pool, queue=celery, priority_weight=7, operator=PythonOperator
[2022-03-03 08:23:03,693] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c0dd5231-296d-4fc8-b813-73e36c0eb42b
[2022-03-03 08:23:03,769] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.4_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:53.436195+00:00, run_end_date=2022-03-03 08:23:00.813697+00:00, run_duration=7.377502, state=success, executor_state=success, try_number=1, max_tries=0, job_id=60, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:03,770] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=13.2_sleep_13, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:47.616113+00:00, run_end_date=2022-03-03 08:23:00.915657+00:00, run_duration=13.299544, state=success, executor_state=success, try_number=1, max_tries=0, job_id=55, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:03,771] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.13.3_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 7edc4fff-cef5-4d22-a384-3bddf36d52b0
[2022-03-03 08:23:03,773] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.5_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 7e4d143d-a9c1-46a4-b4c7-d1cbc6bb1cb0
[2022-03-03 08:23:04,071] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.5.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.6_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:04,073] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:23:04,073] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:04,074] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:04,074] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.5.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.6_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:04,079] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.4_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:04,079] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.4_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:04,080] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.6_sleep_18', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:04,080] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.6_sleep_18', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:04,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.4_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:04,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.6_sleep_18 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:04,671] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.3_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:04,682] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.6_sleep_18 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 94171010-45e7-4d88-bb7c-c5f8870955d3
[2022-03-03 08:23:04,683] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.3_sleep_12, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:50.355610+00:00, run_end_date=2022-03-03 08:23:02.920833+00:00, run_duration=12.565223, state=success, executor_state=success, try_number=1, max_tries=0, job_id=57, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:04,683] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.4_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to b07cbaaf-37cf-478a-aabb-39b0cf8bc967
[2022-03-03 08:23:06,045] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.7.4_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:06,050] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:06,050] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:06,062] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.7.4_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:06,069] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.4_sleep_14', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:06,069] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.4_sleep_14', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:06,275] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.4_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:06,275] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.5_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:06,275] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.3_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:06,287] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.5_sleep_16, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:47.559047+00:00, run_end_date=2022-03-03 08:23:03.883655+00:00, run_duration=16.324608, state=success, executor_state=success, try_number=1, max_tries=0, job_id=54, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:06,287] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.4_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 97c495fc-b737-4b37-bffc-c7d78944aa51
[2022-03-03 08:23:06,287] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.3_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:00.699463+00:00, run_end_date=2022-03-03 08:23:05.720431+00:00, run_duration=5.020968, state=success, executor_state=success, try_number=1, max_tries=0, job_id=68, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:07,758] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:07,763] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:07,763] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:07,764] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:07,768] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.6_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:07,768] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.6_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:07,817] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.6_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:07,818] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.5_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:07,824] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.5_sleep_9, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:56.630213+00:00, run_end_date=2022-03-03 08:23:06.037735+00:00, run_duration=9.407522, state=success, executor_state=success, try_number=1, max_tries=0, job_id=62, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:07,824] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to d5e5fe7e-577a-433d-b6b7-c3a215bc3fd7
[2022-03-03 08:23:09,110] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.13.4_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:09,114] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:09,114] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:09,117] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.13.4_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:09,120] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='13.4_sleep_20', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:09,120] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '13.4_sleep_20', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:09,197] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.4_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:09,197] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.3_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:09,271] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=13.3_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:04.072125+00:00, run_end_date=2022-03-03 08:23:07.909157+00:00, run_duration=3.837032, state=success, executor_state=success, try_number=1, max_tries=0, job_id=71, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:09,271] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.13.4_sleep_20 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f54c87de-78d1-43a5-8fd1-e97d4d108e7d
[2022-03-03 08:23:10,427] {scheduler_job.py:311} INFO - 4 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.5_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.4_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.3_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:10,429] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 4 task instances ready to be queued
[2022-03-03 08:23:10,430] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:23:10,430] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:23:10,430] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:10,430] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:10,431] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.5_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.5.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.12.4_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.10.3_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:10,433] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.5_sleep_2', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:23:10,434] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.5_sleep_2', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:10,434] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.5_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:10,434] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.5_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:10,434] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='12.4_sleep_16', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:10,434] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '12.4_sleep_16', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:10,434] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='10.3_sleep_14', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:10,434] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '10.3_sleep_14', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:11,280] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.5_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:11,281] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.5_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:11,281] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.4_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:11,281] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.3_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:11,281] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.2_sleep_11 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:11,281] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.3_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:11,283] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.4_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:11,283] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.4_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:11,375] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=12.3_sleep_9, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:00.048077+00:00, run_end_date=2022-03-03 08:23:09.792200+00:00, run_duration=9.744123, state=success, executor_state=success, try_number=1, max_tries=0, job_id=67, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:11,375] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.4_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:04.288797+00:00, run_end_date=2022-03-03 08:23:09.106590+00:00, run_duration=4.817793, state=success, executor_state=success, try_number=1, max_tries=0, job_id=73, pool=default_pool, queue=celery, priority_weight=6, operator=PythonOperator
[2022-03-03 08:23:11,376] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=10.2_sleep_11, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:57.941375+00:00, run_end_date=2022-03-03 08:23:09.579855+00:00, run_duration=11.63848, state=success, executor_state=success, try_number=1, max_tries=0, job_id=64, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:11,376] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.5_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c8e3586b-1f16-420f-828a-d17e1285d32a
[2022-03-03 08:23:11,376] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 36c037d9-7507-47a0-b5a8-c3db80d9601d
[2022-03-03 08:23:11,376] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.10.3_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 4b33346f-1dc3-4369-9515-d7bb27d1b718
[2022-03-03 08:23:11,376] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.12.4_sleep_16 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 5b93c40b-b3a7-43d6-b968-197812f42b30
[2022-03-03 08:23:11,376] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.4_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:05.272275+00:00, run_end_date=2022-03-03 08:23:09.593047+00:00, run_duration=4.320772, state=success, executor_state=success, try_number=1, max_tries=0, job_id=75, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:11,778] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.14.6_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:11,782] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:11,782] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:11,783] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.14.6_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:11,791] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.6_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:11,791] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.6_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:12,075] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.6_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:12,075] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.5_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:12,089] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.6_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 43fe4176-91ef-4946-aef7-9c452ad7785d
[2022-03-03 08:23:12,089] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.5_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:04.992335+00:00, run_end_date=2022-03-03 08:23:10.575113+00:00, run_duration=5.582778, state=success, executor_state=success, try_number=1, max_tries=0, job_id=74, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:13,707] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:13,709] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:13,709] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:13,710] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:13,712] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.6_sleep_5', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:23:13,712] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.6_sleep_5', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:13,812] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.6_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:13,812] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.5_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:13,818] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.5_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:01.213221+00:00, run_end_date=2022-03-03 08:23:12.790189+00:00, run_duration=11.576968, state=success, executor_state=success, try_number=1, max_tries=0, job_id=69, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:23:13,818] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.6_sleep_5 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to eb2b9cac-1466-414e-9c8d-053b00be2728
[2022-03-03 08:23:15,044] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.7_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.4_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:15,047] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:23:15,047] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:15,047] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:15,048] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.7_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.9.4_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:15,050] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.7_sleep_10', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:15,051] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.7_sleep_10', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:15,051] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='9.4_sleep_12', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:15,052] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '9.4_sleep_12', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:15,373] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.7_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:15,373] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.4_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:15,373] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.3_sleep_17 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:15,373] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.6_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:15,386] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.9.4_sleep_12 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 1f5fd1a8-4104-46cb-a67b-52f00cc18a19
[2022-03-03 08:23:15,386] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.6_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:08.372745+00:00, run_end_date=2022-03-03 08:23:13.697893+00:00, run_duration=5.325148, state=success, executor_state=success, try_number=1, max_tries=0, job_id=78, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:15,386] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.7_sleep_10 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 2bc38f13-470e-4914-ad3c-ab92c4663e7e
[2022-03-03 08:23:15,386] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=9.3_sleep_17, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:56.946516+00:00, run_end_date=2022-03-03 08:23:14.159336+00:00, run_duration=17.21282, state=success, executor_state=success, try_number=1, max_tries=0, job_id=63, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:16,659] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.5_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:16,662] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 2 task instances ready to be queued
[2022-03-03 08:23:16,662] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:16,662] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:16,662] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.5_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:16,667] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.6_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue celery
[2022-03-03 08:23:16,667] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.6_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:16,668] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.5_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:16,668] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.5_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:16,902] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.6_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:16,902] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.5_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:16,903] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.4_sleep_13 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:16,903] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.5_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:16,913] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to d9470d61-5b9c-4806-9e5d-ceed5bd64f79
[2022-03-03 08:23:16,913] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.5_sleep_2, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:11.995349+00:00, run_end_date=2022-03-03 08:23:15.109503+00:00, run_duration=3.114154, state=success, executor_state=success, try_number=1, max_tries=0, job_id=81, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:23:16,915] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.4_sleep_13, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:02.240212+00:00, run_end_date=2022-03-03 08:23:15.592490+00:00, run_duration=13.352278, state=success, executor_state=success, try_number=1, max_tries=0, job_id=70, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:16,915] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.5_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to a1bc9bf1-df2b-4cf0-91ba-a303915cdca6
[2022-03-03 08:23:18,256] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.5.6_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:18,259] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:18,259] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:18,260] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.5.6_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:18,263] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='5.6_sleep_14', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:18,263] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '5.6_sleep_14', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:18,314] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.6_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:18,315] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.5_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:18,323] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.5.6_sleep_14 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c5a44c57-e7ce-4552-9379-303c13a4f521
[2022-03-03 08:23:18,323] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.5_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:12.376992+00:00, run_end_date=2022-03-03 08:23:17.411225+00:00, run_duration=5.034233, state=success, executor_state=success, try_number=1, max_tries=0, job_id=82, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:19,486] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.7_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:19,488] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 113 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:19,488] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 15/16 running and queued tasks
[2022-03-03 08:23:19,489] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.7_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:19,494] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.7_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:19,495] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.7_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:19,585] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.7_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:19,585] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.6_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:19,593] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.6_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:17.371788+00:00, run_end_date=2022-03-03 08:23:18.728372+00:00, run_duration=1.356584, state=success, executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:19,593] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.7_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 395181f0-da43-4d50-bcc6-f0449e64c842
[2022-03-03 08:23:20,847] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:20,850] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 115 open slots and 2 task instances ready to be queued
[2022-03-03 08:23:20,851] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 13/16 running and queued tasks
[2022-03-03 08:23:20,851] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:20,852] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:20,856] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.7_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:23:20,856] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.7_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:20,856] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.6_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:20,857] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.6_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:21,267] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.7_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:21,268] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.6_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:21,268] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.6.2_sleep_27 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:21,268] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.6_sleep_5 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:21,268] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.5_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:21,284] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.6_sleep_5, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:14.331433+00:00, run_end_date=2022-03-03 08:23:19.563751+00:00, run_duration=5.232318, state=success, executor_state=success, try_number=1, max_tries=0, job_id=85, pool=default_pool, queue=celery, priority_weight=4, operator=PythonOperator
[2022-03-03 08:23:21,285] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=6.2_sleep_27, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:53.018162+00:00, run_end_date=2022-03-03 08:23:20.521754+00:00, run_duration=27.503592, state=success, executor_state=success, try_number=1, max_tries=0, job_id=59, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:21,285] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to dd1e284a-4faf-4d76-b4a7-d6e46812fa46
[2022-03-03 08:23:21,285] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.5_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:17.287388+00:00, run_end_date=2022-03-03 08:23:20.624635+00:00, run_duration=3.337247, state=success, executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:21,286] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.6_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to b50746ca-2f37-48a0-bdb1-b479f3023fe4
[2022-03-03 08:23:21,564] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.7.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:21,569] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 114 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:21,569] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 14/16 running and queued tasks
[2022-03-03 08:23:21,571] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.7.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:21,577] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='7.5_sleep_4', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:21,579] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '7.5_sleep_4', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:21,871] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.5_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:21,881] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.7.5_sleep_4 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 879cbe78-5bdb-4e23-b746-8818a360fa38
[2022-03-03 08:23:22,194] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.4_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:22,271] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.4_sleep_14, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:06.972598+00:00, run_end_date=2022-03-03 08:23:21.367534+00:00, run_duration=14.394936, state=success, executor_state=success, try_number=1, max_tries=0, job_id=77, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:23,113] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.11.2_sleep_24 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:23,118] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=11.2_sleep_24, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:58.014944+00:00, run_end_date=2022-03-03 08:23:22.468909+00:00, run_duration=24.453965, state=success, executor_state=success, try_number=1, max_tries=0, job_id=65, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:24,197] {scheduler_job.py:311} INFO - 3 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.8_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.7_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.7_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:24,199] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 3 task instances ready to be queued
[2022-03-03 08:23:24,200] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 10/16 running and queued tasks
[2022-03-03 08:23:24,200] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 11/16 running and queued tasks
[2022-03-03 08:23:24,200] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:23:24,201] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.8_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.14.7_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.16.7_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:24,204] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.8_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:24,204] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.8_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:24,204] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='14.7_sleep_9', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:24,204] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '14.7_sleep_9', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:24,204] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='16.7_sleep_3', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:24,206] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '16.7_sleep_3', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:24,783] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.8_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:24,784] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.7_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:24,784] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.7_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:24,784] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.6_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:24,784] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.7_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:24,785] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.6_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:24,872] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.8_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 1ddd6386-a622-4c30-80aa-9f6158ec8931
[2022-03-03 08:23:24,872] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.6_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:13.772836+00:00, run_end_date=2022-03-03 08:23:24.128199+00:00, run_duration=10.355363, state=success, executor_state=success, try_number=1, max_tries=0, job_id=84, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:24,872] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.6_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:21.971343+00:00, run_end_date=2022-03-03 08:23:23.721262+00:00, run_duration=1.749919, state=success, executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:24,872] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.16.7_sleep_3 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to c5d53c7e-cc45-41d2-bea1-92b76353c057
[2022-03-03 08:23:24,872] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.14.7_sleep_9 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 93ff9ea5-8ab4-4f8e-8736-00c07ad635a3
[2022-03-03 08:23:24,873] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.7_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:22.172991+00:00, run_end_date=2022-03-03 08:23:23.915044+00:00, run_duration=1.742053, state=success, executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:25,081] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.8_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:25,087] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 116 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:25,088] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:23:25,164] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.8_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:25,169] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.8_sleep_6', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:23:25,169] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.8_sleep_6', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:25,473] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.8_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:25,473] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.1.2_sleep_24 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:25,473] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.7_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:25,489] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=1.2_sleep_24, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:59.813373+00:00, run_end_date=2022-03-03 08:23:24.686363+00:00, run_duration=24.87299, state=success, executor_state=success, try_number=1, max_tries=0, job_id=66, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:25,489] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.7_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:19.961417+00:00, run_end_date=2022-03-03 08:23:24.185635+00:00, run_duration=4.224218, state=success, executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=celery, priority_weight=3, operator=PythonOperator
[2022-03-03 08:23:25,489] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.8_sleep_6 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f06ae323-90ca-433d-b7e1-e5bec441b862
[2022-03-03 08:23:26,776] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.15.8_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:26,778] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 117 open slots and 2 task instances ready to be queued
[2022-03-03 08:23:26,778] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 11/16 running and queued tasks
[2022-03-03 08:23:26,778] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 12/16 running and queued tasks
[2022-03-03 08:23:26,779] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.15.8_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
	<TaskInstance: sixteen_sleep_grains.3.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:26,782] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='15.8_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:26,782] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '15.8_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:26,782] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='3.7_sleep_1', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:26,782] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '3.7_sleep_1', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:27,076] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.8_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:27,077] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.7_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:27,077] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.6_sleep_18 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:27,077] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.7_sleep_10 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:27,087] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.3.7_sleep_1 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 00520f93-6793-48e7-95b5-5208e993a341
[2022-03-03 08:23:27,088] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.7_sleep_10, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:15.798932+00:00, run_end_date=2022-03-03 08:23:26.377860+00:00, run_duration=10.578928, state=success, executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:27,088] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.15.8_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 0516da5b-34fe-4f72-a5a9-724e292ea246
[2022-03-03 08:23:27,088] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.6_sleep_18, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:06.797979+00:00, run_end_date=2022-03-03 08:23:25.271446+00:00, run_duration=18.473467, state=success, executor_state=success, try_number=1, max_tries=0, job_id=76, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:27,378] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.10.3_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:27,391] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=10.3_sleep_14, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:11.766401+00:00, run_end_date=2022-03-03 08:23:26.905313+00:00, run_duration=15.138912, state=success, executor_state=success, try_number=1, max_tries=0, job_id=80, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:28,480] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.2.4_sleep_23 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:28,480] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.7.5_sleep_4 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:28,487] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=2.4_sleep_23, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:04.562789+00:00, run_end_date=2022-03-03 08:23:28.332314+00:00, run_duration=23.769525, state=success, executor_state=success, try_number=1, max_tries=0, job_id=72, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:28,487] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=7.5_sleep_4, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:22.794972+00:00, run_end_date=2022-03-03 08:23:27.091036+00:00, run_duration=4.296064, state=success, executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:29,657] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.4.9_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:29,660] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 122 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:29,660] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 6/16 running and queued tasks
[2022-03-03 08:23:29,661] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.4.9_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:29,666] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='4.9_sleep_7', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:29,666] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '4.9_sleep_7', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:29,777] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.9_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:29,777] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.9.4_sleep_12 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:29,777] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.8_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:29,777] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.16.7_sleep_3 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:29,778] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.3.7_sleep_1 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:29,787] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=3.7_sleep_1, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:27.633196+00:00, run_end_date=2022-03-03 08:23:28.908303+00:00, run_duration=1.275107, state=success, executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:29,787] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.8_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:25.478327+00:00, run_end_date=2022-03-03 08:23:29.107270+00:00, run_duration=3.628943, state=success, executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:29,787] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=9.4_sleep_12, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:16.009303+00:00, run_end_date=2022-03-03 08:23:28.452222+00:00, run_duration=12.442919, state=success, executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:29,787] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.4.9_sleep_7 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to 9135dee6-d0e6-4596-b14f-6e4cef8028f6
[2022-03-03 08:23:29,788] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=16.7_sleep_3, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:25.605363+00:00, run_end_date=2022-03-03 08:23:29.294114+00:00, run_duration=3.688751, state=success, executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:29,937] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.12.4_sleep_16 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:29,969] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=12.4_sleep_16, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:12.583832+00:00, run_end_date=2022-03-03 08:23:29.648991+00:00, run_duration=17.065159, state=success, executor_state=success, try_number=1, max_tries=0, job_id=83, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:31,046] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.13.4_sleep_20 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:31,054] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=13.4_sleep_20, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:09.999978+00:00, run_end_date=2022-03-03 08:23:30.221086+00:00, run_duration=20.221108, state=success, executor_state=success, try_number=1, max_tries=0, job_id=79, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:33,297] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: sixteen_sleep_grains.8.9_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:33,301] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 125 open slots and 1 task instances ready to be queued
[2022-03-03 08:23:33,301] {scheduler_job.py:381} INFO - DAG sixteen_sleep_grains has 3/16 running and queued tasks
[2022-03-03 08:23:33,301] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: sixteen_sleep_grains.8.9_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [scheduled]>
[2022-03-03 08:23:33,304] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='sixteen_sleep_grains', task_id='8.9_sleep_2', run_id='scheduled__2022-03-03T08:17:02.672519+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue celery
[2022-03-03 08:23:33,304] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'sixteen_sleep_grains', '8.9_sleep_2', 'scheduled__2022-03-03T08:17:02.672519+00:00', '--local', '--subdir', 'DAGS_FOLDER/stressballs.py']
[2022-03-03 08:23:33,380] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.9_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status queued for try_number 1
[2022-03-03 08:23:33,381] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.8_sleep_6 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:33,443] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.8_sleep_6, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:26.278060+00:00, run_end_date=2022-03-03 08:23:32.801927+00:00, run_duration=6.523867, state=success, executor_state=success, try_number=1, max_tries=0, job_id=98, pool=default_pool, queue=celery, priority_weight=2, operator=PythonOperator
[2022-03-03 08:23:33,443] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: sixteen_sleep_grains.8.9_sleep_2 scheduled__2022-03-03T08:17:02.672519+00:00 [queued]> to f2aa9911-e265-4869-b3d7-84d475f8b613
[2022-03-03 08:23:33,567] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.5.6_sleep_14 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:33,572] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=5.6_sleep_14, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:19.003186+00:00, run_end_date=2022-03-03 08:23:33.248150+00:00, run_duration=14.244964, state=success, executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:35,748] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.14.7_sleep_9 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:35,748] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.15.8_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:35,754] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=14.7_sleep_9, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:25.885556+00:00, run_end_date=2022-03-03 08:23:35.598093+00:00, run_duration=9.712537, state=success, executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:35,754] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=15.8_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:27.575789+00:00, run_end_date=2022-03-03 08:23:34.819744+00:00, run_duration=7.243955, state=success, executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:36,829] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.8.9_sleep_2 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:36,836] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=8.9_sleep_2, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:33.776940+00:00, run_end_date=2022-03-03 08:23:36.001521+00:00, run_duration=2.224581, state=success, executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:23:38,138] {dagrun.py:549} INFO - Marking run <DagRun sixteen_sleep_grains @ 2022-03-03 08:17:02.672519+00:00: scheduled__2022-03-03T08:17:02.672519+00:00, externally triggered: False> successful
[2022-03-03 08:23:38,138] {dagrun.py:594} INFO - DagRun Finished: dag_id=sixteen_sleep_grains, execution_date=2022-03-03 08:17:02.672519+00:00, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:22:11.410995+00:00, run_end_date=2022-03-03 08:23:38.138681+00:00, run_duration=86.727686, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2022-03-03 08:17:02.672519+00:00, data_interval_end=2022-03-03 08:22:09.672519+00:00, dag_hash=849a3a44e3354225c1077905616f375c
[2022-03-03 08:23:38,150] {dag.py:2921} INFO - Setting next_dagrun for sixteen_sleep_grains to 2022-03-03T08:22:09.672519+00:00, run_after=2022-03-03T08:27:16.672519+00:00
[2022-03-03 08:23:38,181] {scheduler_job.py:552} INFO - Executor reports execution of sixteen_sleep_grains.4.9_sleep_7 run_id=scheduled__2022-03-03T08:17:02.672519+00:00 exited with status success for try_number 1
[2022-03-03 08:23:38,188] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=sixteen_sleep_grains, task_id=4.9_sleep_7, run_id=scheduled__2022-03-03T08:17:02.672519+00:00, run_start_date=2022-03-03 08:23:30.097323+00:00, run_end_date=2022-03-03 08:23:37.284166+00:00, run_duration=7.186843, state=success, executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=celery, priority_weight=1, operator=PythonOperator
[2022-03-03 08:24:39,446] {scheduler_job.py:982} INFO - DAG example_sql_sensor is at (or above) max_active_runs (1 of 1), not creating any more runs
[2022-03-03 08:24:39,493] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:24:39,495] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-03-03 08:24:39,496] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 0/16 running and queued tasks
[2022-03-03 08:24:39,496] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:24:39,499] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='prepare_table', run_id='scheduled__2022-03-03T08:21:37.673470+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue celery
[2022-03-03 08:24:39,499] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'prepare_table', 'scheduled__2022-03-03T08:21:37.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:24:39,562] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.prepare_table run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:24:39,570] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.prepare_table scheduled__2022-03-03T08:21:37.673470+00:00 [queued]> to 6ede29c5-47fd-43c0-af2a-50136ee7271c
[2022-03-03 08:24:40,735] {scheduler_job.py:311} INFO - 2 tasks up for execution:
	<TaskInstance: example_sql_sensor.sleep_30 scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
	<TaskInstance: example_sql_sensor.sql_sensor scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:24:40,737] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued
[2022-03-03 08:24:40,737] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 0/16 running and queued tasks
[2022-03-03 08:24:40,737] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 1/16 running and queued tasks
[2022-03-03 08:24:40,737] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: example_sql_sensor.sleep_30 scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
	<TaskInstance: example_sql_sensor.sql_sensor scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:24:40,740] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='sleep_30', run_id='scheduled__2022-03-03T08:21:37.673470+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue celery
[2022-03-03 08:24:40,740] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'sleep_30', 'scheduled__2022-03-03T08:21:37.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:24:40,741] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='sql_sensor', run_id='scheduled__2022-03-03T08:21:37.673470+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:24:40,741] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'sql_sensor', 'scheduled__2022-03-03T08:21:37.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:24:40,966] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.sleep_30 run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:24:40,967] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.sql_sensor run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:24:40,967] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.prepare_table run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status success for try_number 1
[2022-03-03 08:24:40,975] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.sql_sensor scheduled__2022-03-03T08:21:37.673470+00:00 [queued]> to 3b5f2b1b-db8c-4fd2-9f19-46c51e502272
[2022-03-03 08:24:40,975] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.sleep_30 scheduled__2022-03-03T08:21:37.673470+00:00 [queued]> to 666efc01-c2d9-4e04-ab11-ea1f8256d71c
[2022-03-03 08:24:40,976] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=example_sql_sensor, task_id=prepare_table, run_id=scheduled__2022-03-03T08:21:37.673470+00:00, run_start_date=2022-03-03 08:24:39.692059+00:00, run_end_date=2022-03-03 08:24:39.974090+00:00, run_duration=0.282031, state=success, executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=celery, priority_weight=5, operator=PythonOperator
[2022-03-03 08:25:11,738] {scheduler_job.py:311} INFO - 1 tasks up for execution:
	<TaskInstance: example_sql_sensor.add_state scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:25:11,741] {scheduler_job.py:353} INFO - Figuring out tasks to run in Pool(name=default_pool) with 127 open slots and 1 task instances ready to be queued
[2022-03-03 08:25:11,741] {scheduler_job.py:381} INFO - DAG example_sql_sensor has 1/16 running and queued tasks
[2022-03-03 08:25:11,742] {scheduler_job.py:457} INFO - Setting the following tasks to queued state:
	<TaskInstance: example_sql_sensor.add_state scheduled__2022-03-03T08:21:37.673470+00:00 [scheduled]>
[2022-03-03 08:25:11,746] {scheduler_job.py:499} INFO - Sending TaskInstanceKey(dag_id='example_sql_sensor', task_id='add_state', run_id='scheduled__2022-03-03T08:21:37.673470+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue celery
[2022-03-03 08:25:11,746] {base_executor.py:88} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_sql_sensor', 'add_state', 'scheduled__2022-03-03T08:21:37.673470+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_sql_sensor.py']
[2022-03-03 08:25:11,802] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.add_state run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status queued for try_number 1
[2022-03-03 08:25:11,803] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.sleep_30 run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status success for try_number 1
[2022-03-03 08:25:11,827] {scheduler_job.py:586} INFO - Setting external_id for <TaskInstance: example_sql_sensor.add_state scheduled__2022-03-03T08:21:37.673470+00:00 [queued]> to 478876fb-9469-4277-8258-e30a4b3cab67
[2022-03-03 08:25:11,827] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=example_sql_sensor, task_id=sleep_30, run_id=scheduled__2022-03-03T08:21:37.673470+00:00, run_start_date=2022-03-03 08:24:41.204035+00:00, run_end_date=2022-03-03 08:25:11.603916+00:00, run_duration=30.399881, state=success, executor_state=success, try_number=1, max_tries=0, job_id=105, pool=default_pool, queue=celery, priority_weight=3, operator=BashOperator
[2022-03-03 08:25:12,478] {scheduler_job.py:552} INFO - Executor reports execution of example_sql_sensor.add_state run_id=scheduled__2022-03-03T08:21:37.673470+00:00 exited with status success for try_number 1
[2022-03-03 08:25:12,487] {scheduler_job.py:595} INFO - TaskInstance Finished: dag_id=example_sql_sensor, task_id=add_state, run_id=scheduled__2022-03-03T08:21:37.673470+00:00, run_start_date=2022-03-03 08:25:11.983401+00:00, run_end_date=2022-03-03 08:25:12.266501+00:00, run_duration=0.2831, state=success, executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=celery, priority_weight=2, operator=PostgresOperator
